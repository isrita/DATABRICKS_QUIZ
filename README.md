# 🚀 Databricks Data Engineering Tests

Welcome to this repository! Here, you will find **three data engineering test projects**, each structured within its own **Databricks notebook**. These projects include **instructions and datasets** embedded within the notebooks.

## 📂 Repository Structure

```
📁 databricks-data-engineering-tests
│── 📄 test1.ipynb  # Data Engineering Test 1
│── 📄 test2.ipynb  # Data Engineering Test 2
│── 📄 test3.ipynb  # Data Engineering Test 3
│── 📄 README.md    # Project Documentation
```

Each notebook:
- Contains **detailed step-by-step instructions** for completing the exercises.
- Includes **data embedded within the notebook** or referenced from an external source.
- Covers different **data engineering tasks**, using **Azure, Databricks, Spark, and Python**.

---

## 📥 How to Import This Repository into Databricks

To run these notebooks in your **Databricks** environment, follow these steps:

### **1️⃣ Download the Repository**
First, clone the repository to your local machine or download it as a ZIP file:

```bash
git clone https://github.com/YOUR_GITHUB_USERNAME/databricks-data-engineering-tests.git
```

Or manually **download the ZIP** from GitHub and extract the files.

---

### **2️⃣ Open Databricks and Navigate to the Workspace**
1. Log in to **Databricks Community Edition** ([Sign In Here](https://community.cloud.databricks.com/)) or your enterprise workspace.
2. In the left sidebar, click on **Workspace**.
3. Select a directory where you want to import the notebooks.

---

### **3️⃣ Import the Notebooks into Databricks**
You can import the notebooks using one of the following methods:

#### **Option 1: Import One Notebook at a Time**
1. Click on the **Dropdown (▼) next to your target folder**.
2. Select **Import**.
3. Choose **"File"** and upload a single `.ipynb` or `.py` notebook from the downloaded folder.
4. Click **Import** to add it to your workspace.

#### **Option 2: Import All Notebooks as a Folder (DBC File)**
If you've exported the entire repository as a `.dbc` file:
1. Go to **Workspace**.
2. Click **Import**.
3. Select **"File"** and upload the `.dbc` archive.
4. Databricks will automatically extract all notebooks into a new folder.

---

### **4️⃣ Run the Notebooks**
1. Open a notebook (e.g., `test1.ipynb`).
2. Click **"Run All"** to execute all cells, or step through them one by one.
3. Follow the instructions provided in each notebook.

---

## 🔧 Troubleshooting
- Ensure your **Databricks cluster is running** before executing the code.
- If you experience **import errors**, check that required **libraries** are installed in your Databricks cluster.
- For **large datasets**, make sure your cluster has enough memory allocated.

---

## 🤝 Contributing
If you’d like to improve or extend these tests, feel free to **fork the repository** and submit a pull request!

---

## 📩 Contact
If you have any questions, feel free to reach out:
- **GitHub:** [isrita](https://github.com/isrita)
- **Email:** israel.bonillad@gmail.com
- **LinkedIn:** [Israel Bonilla](https://www.linkedin.com/in/israel-bonilla-de-la-cruz/)

---

🔥 **Happy coding and enjoy working with Databricks!** 🚀
