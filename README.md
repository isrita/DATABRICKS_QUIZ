# ğŸš€ Databricks Data Engineering Tests

Welcome to this repository! Here, you will find **three data engineering test projects**, each structured within its own **Databricks notebook**. These projects include **instructions and datasets** embedded within the notebooks.

## ğŸ“‚ Repository Structure

```
ğŸ“ databricks-data-engineering-tests
â”‚â”€â”€ ğŸ“„ test1.ipynb  # Data Engineering Test 1
â”‚â”€â”€ ğŸ“„ test2.ipynb  # Data Engineering Test 2
â”‚â”€â”€ ğŸ“„ test3.ipynb  # Data Engineering Test 3
â”‚â”€â”€ ğŸ“„ README.md    # Project Documentation
```

Each notebook:
- Contains **detailed step-by-step instructions** for completing the exercises.
- Includes **data embedded within the notebook** or referenced from an external source.
- Covers different **data engineering tasks**, using **Azure, Databricks, Spark, and Python**.

---

## ğŸ“¥ How to Import This Repository into Databricks

To run these notebooks in your **Databricks** environment, follow these steps:

### **1ï¸âƒ£ Download the Repository**
First, clone the repository to your local machine or download it as a ZIP file:

```bash
git clone https://github.com/YOUR_GITHUB_USERNAME/databricks-data-engineering-tests.git
```

Or manually **download the ZIP** from GitHub and extract the files.

---

### **2ï¸âƒ£ Open Databricks and Navigate to the Workspace**
1. Log in to **Databricks Community Edition** ([Sign In Here](https://community.cloud.databricks.com/)) or your enterprise workspace.
2. In the left sidebar, click on **Workspace**.
3. Select a directory where you want to import the notebooks.

---

### **3ï¸âƒ£ Import the Notebooks into Databricks**
You can import the notebooks using one of the following methods:

#### **Option 1: Import One Notebook at a Time**
1. Click on the **Dropdown (â–¼) next to your target folder**.
2. Select **Import**.
3. Choose **"File"** and upload a single `.ipynb` or `.py` notebook from the downloaded folder.
4. Click **Import** to add it to your workspace.

#### **Option 2: Import All Notebooks as a Folder (DBC File)**
If you've exported the entire repository as a `.dbc` file:
1. Go to **Workspace**.
2. Click **Import**.
3. Select **"File"** and upload the `.dbc` archive.
4. Databricks will automatically extract all notebooks into a new folder.

---

### **4ï¸âƒ£ Run the Notebooks**
1. Open a notebook (e.g., `test1.ipynb`).
2. Click **"Run All"** to execute all cells, or step through them one by one.
3. Follow the instructions provided in each notebook.

---

## ğŸ”§ Troubleshooting
- Ensure your **Databricks cluster is running** before executing the code.
- If you experience **import errors**, check that required **libraries** are installed in your Databricks cluster.
- For **large datasets**, make sure your cluster has enough memory allocated.

---

## ğŸ¤ Contributing
If youâ€™d like to improve or extend these tests, feel free to **fork the repository** and submit a pull request!

---

## ğŸ“© Contact
If you have any questions, feel free to reach out:
- **GitHub:** [isrita](https://github.com/isrita)
- **Email:** israel.bonillad@gmail.com
- **LinkedIn:** [Israel Bonilla](https://www.linkedin.com/in/israel-bonilla-de-la-cruz/)

---

ğŸ”¥ **Happy coding and enjoy working with Databricks!** ğŸš€
